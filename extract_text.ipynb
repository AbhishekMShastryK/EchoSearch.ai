{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lecture_videos\\GAIT Teams Lecture-20240829_184346-Meeting Recording.mp4...\n",
      "MoviePy - Writing audio in C:\\Users\\abhis\\AppData\\Local\\Temp\\tmpx8vdvdvx.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Processing lecture_videos\\GAIT Teams Lecture-20240903_184512-Meeting Recording.mp4...\n",
      "MoviePy - Writing audio in C:\\Users\\abhis\\AppData\\Local\\Temp\\tmprtg83nd8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Processing lecture_videos\\GAIT Teams Lecture-20240905_184245-Meeting Recording.mp4...\n",
      "MoviePy - Writing audio in C:\\Users\\abhis\\AppData\\Local\\Temp\\tmpond93iwb.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Processing lecture_videos\\GAIT Teams Lecture-20240910_184443-Meeting Recording.mp4...\n",
      "MoviePy - Writing audio in C:\\Users\\abhis\\AppData\\Local\\Temp\\tmpuftjvnqx.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Processing lecture_videos\\GAIT Teams Lecture-20241008_184347-Meeting Recording.mp4...\n",
      "MoviePy - Writing audio in C:\\Users\\abhis\\AppData\\Local\\Temp\\tmpx6lgrkji.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Processing lecture_videos\\GAIT Teams Lecture-20241022_184138-Meeting Recording.mp4...\n",
      "MoviePy - Writing audio in C:\\Users\\abhis\\AppData\\Local\\Temp\\tmpb3cm49gb.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Processing lecture_videos\\GAIT Teams Lecture-20241029_184026-Meeting Recording.mp4...\n",
      "MoviePy - Writing audio in C:\\Users\\abhis\\AppData\\Local\\Temp\\tmp2tc141c5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Transcriptions have been saved to transcriptions.xlsx\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import moviepy.editor as mp\n",
    "import tempfile\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the Whisper model for automatic speech recognition\n",
    "asr = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-large-v3-turbo\")\n",
    "\n",
    "def extract_audio_from_video(video_path):\n",
    "    # Load the video and extract the audio as a separate file\n",
    "    video = mp.VideoFileClip(video_path)\n",
    "    temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
    "    video.audio.write_audiofile(temp_audio.name)\n",
    "    video.close()  # Close the VideoFileClip to release resources\n",
    "    return temp_audio\n",
    "\n",
    "def split_audio(audio_path, segment_duration=60):\n",
    "    # Load the audio file using librosa\n",
    "    audio, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Calculate the total duration of the audio and split it into segments of specified duration\n",
    "    total_duration = librosa.get_duration(y=audio, sr=sr)\n",
    "    segments = []\n",
    "\n",
    "    for start in range(0, int(total_duration), segment_duration):\n",
    "        end = min(start + segment_duration, int(total_duration))\n",
    "        segment = audio[start * sr:end * sr]\n",
    "        \n",
    "        # Save each segment to a temporary file\n",
    "        temp_segment = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
    "        sf.write(temp_segment.name, segment, sr)\n",
    "        segments.append((temp_segment, start, end))\n",
    "\n",
    "    return segments\n",
    "\n",
    "def transcribe_and_beautify_audio_segments(segments):\n",
    "    # Transcribe and beautify each audio segment\n",
    "    transcriptions = []\n",
    "    previous_text_fragment = \"\"\n",
    "\n",
    "    for segment, start, end in segments:\n",
    "        # Transcribe the audio segment using the Whisper model\n",
    "        transcription = asr(segment.name, return_timestamps=True)\n",
    "        raw_text = transcription['text']\n",
    "\n",
    "        # If there was an incomplete sentence from the previous segment, prepend it\n",
    "        if previous_text_fragment:\n",
    "            raw_text = previous_text_fragment + \" \" + raw_text\n",
    "\n",
    "        # Check if the raw_text ends with a complete sentence\n",
    "        if not raw_text.endswith(('.', '!', '?')):\n",
    "            # If it ends with an incomplete sentence, store it for the next segment\n",
    "            # Extract the incomplete sentence\n",
    "            sentence_endings = re.compile(r'(?<=[.!?])\\s+')\n",
    "            sentences = sentence_endings.split(raw_text)\n",
    "            if len(sentences) > 1:\n",
    "                previous_text_fragment = sentences[-1].strip()\n",
    "            else:\n",
    "                previous_text_fragment = raw_text.strip()\n",
    "        else:\n",
    "            previous_text_fragment = \"\"\n",
    "\n",
    "        # Append the transcription along with its start and end timestamps\n",
    "        transcriptions.append({\n",
    "            'start_time': start,\n",
    "            'end_time': end,\n",
    "            'raw_text': raw_text\n",
    "        })\n",
    "\n",
    "        # Clean up the temporary segment file\n",
    "        segment.close()\n",
    "        os.unlink(segment.name)\n",
    "    \n",
    "    # Handle any remaining incomplete sentence from the last segment\n",
    "    if previous_text_fragment:\n",
    "        # Add the incomplete sentence to the last transcription\n",
    "        transcriptions[-1]['raw_text'] += ' ' + previous_text_fragment\n",
    "\n",
    "    return transcriptions\n",
    "\n",
    "# Specify the folder containing your video files\n",
    "video_folder = \"lecture_videos\"  # Replace with the path to your video folder\n",
    "\n",
    "# Supported video file extensions\n",
    "video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv')\n",
    "\n",
    "# List all video files in the folder\n",
    "video_files = [os.path.join(video_folder, f) for f in os.listdir(video_folder)\n",
    "               if f.lower().endswith(video_extensions)]\n",
    "\n",
    "# Check if any video files are found\n",
    "if not video_files:\n",
    "    print(f\"No video files found in {video_folder}\")\n",
    "else:\n",
    "    all_transcriptions = []\n",
    "\n",
    "    for video_file in video_files:\n",
    "        print(f\"Processing {video_file}...\")\n",
    "        try:\n",
    "\n",
    "            # Extract the video name without extension\n",
    "            video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
    "\n",
    "            # Extract audio from the local video file\n",
    "            audio_file = extract_audio_from_video(video_file)\n",
    "\n",
    "            # Split the audio into smaller segments of 60 seconds each\n",
    "            segments = split_audio(audio_file.name)\n",
    "\n",
    "            # Transcribe and beautify each audio segment\n",
    "            corrected_transcriptions = transcribe_and_beautify_audio_segments(segments)\n",
    "\n",
    "            # Add the video filename to each transcription\n",
    "            for transcription in corrected_transcriptions:\n",
    "                transcription['video'] = video_name\n",
    "\n",
    "            # Append the transcriptions to the list\n",
    "            all_transcriptions.extend(corrected_transcriptions)\n",
    "\n",
    "            # Clean up the temporary audio file\n",
    "            audio_file.close()\n",
    "            os.unlink(audio_file.name)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {video_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Create a DataFrame to store the corrected transcriptions with timestamps and video names\n",
    "    df = pd.DataFrame(all_transcriptions)\n",
    "\n",
    "    # Reorder columns for better readability\n",
    "    df = df[['video', 'start_time', 'end_time', 'raw_text']]\n",
    "\n",
    "    # Save the DataFrame to an Excel file\n",
    "    output_excel_path = \"transcriptions.xlsx\"\n",
    "    df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "    # Print the path to the Excel file\n",
    "    print(f\"Transcriptions have been saved to {output_excel_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
